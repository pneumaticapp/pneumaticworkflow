# Generated by Django 2.2 on 2023-05-04 12:45

import django.core.validators
from django.db import migrations, models
import django.db.models.deletion


class Migration(migrations.Migration):

    initial = True

    dependencies = [
    ]

    operations = [
        migrations.CreateModel(
            name='OpenAiPrompt',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('is_active', models.BooleanField(default=True)),
                ('target', models.CharField(choices=[('get_steps', 'Get template steps')], default='get_steps', max_length=200)),
                ('model', models.CharField(choices=[('gpt-3.5-turbo', 'gpt-3.5-turbo')], default='gpt-3.5-turbo', max_length=200)),
                ('temperature', models.IntegerField(default=1, help_text='Value between 0 and 2. What sampling temperature to use.Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.', validators=[django.core.validators.MinValueValidator(0), django.core.validators.MaxValueValidator(2)])),
                ('top_p', models.IntegerField(default=1, help_text='Value between 0 and 2. An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. <b>We generally recommend altering this or temperature but not both.</b>', validators=[django.core.validators.MinValueValidator(0), django.core.validators.MaxValueValidator(2)])),
                ('presence_penalty', models.IntegerField(default=0, help_text='Value between -2 and 2. APositive values penalize new tokens based on whether they appear in the text so far, increasing the model\'s likelihood to talk about new topics. <a href="https://platform.openai.com/docs/api-reference/parameter-details">More.</a>', validators=[django.core.validators.MinValueValidator(-2), django.core.validators.MaxValueValidator(2)])),
                ('frequency_penalty', models.IntegerField(default=0, help_text='Value between -2 and 2. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model\'s likelihood to repeat the same line verbatim. <a href="https://platform.openai.com/docs/api-reference/parameter-details">More.</a>', validators=[django.core.validators.MinValueValidator(-2), django.core.validators.MaxValueValidator(2)])),
                ('comment', models.TextField(blank=True, help_text='Optional Notes', null=True)),
                ('date_created', models.DateTimeField(auto_now=True)),
                ('date_changed', models.DateTimeField(auto_now_add=True)),
            ],
            options={
                'ordering': ('date_created',),
            },
        ),
        migrations.CreateModel(
            name='OpenAiMessage',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('is_active', models.BooleanField(default=True)),
                ('order', models.IntegerField(validators=[django.core.validators.MinValueValidator(1)])),
                ('role', models.CharField(choices=[('user', 'user'), ('system', 'system'), ('assistant', 'assistant')], default='user', help_text='The role of the author of this message.', max_length=100)),
                ('content', models.TextField(help_text='The contents of the message.')),
                ('prompt', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, to='ai.OpenAiPrompt')),
            ],
            options={
                'verbose_name': 'Prompt message',
                'ordering': ('order',),
            },
        ),
    ]
